{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('UCSD-GENIE/ClimaQA', data_files=\"climaqa_gold/ffq/ffq_benchmark.csv\")\n",
    "dataset = dataset['train']\n",
    "\n",
    "\n",
    "ffq_df = dataset.to_pandas()\n",
    "ffq_df = ffq_df[ffq_df['Validation'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quesition: How would the climate be impacted if there was a significant decrease in anthropogenic aerosol particles affecting cloud droplet concentrations?\n",
      "Reference Answer: If there was a significant decrease in anthropogenic aerosol particles affecting cloud droplet concentrations, it would lead to a decrease in cloud albedo and a reduction in the fundamental cooling effect of aerosol via the interaction with liquid clouds.\n",
      "\n",
      "LLM: gpt-3.5-turbo\n",
      "\tGenerated Answer: A significant decrease in anthropogenic aerosol particles affecting cloud droplet concentrations would likely lead to reduced cloud cover and potentially contribute to a warming effect on the climate due to less sunlight being reflected back into space.\n",
      "\n",
      "\tBleu: 0.656\n",
      "\tBert: 0.926\n",
      "\tFA Score: 0.898\n",
      "LLM: gpt-4o\n",
      "\tGenerated Answer: A significant decrease in anthropogenic aerosol particles would likely lead to less reflective clouds, which could reduce the cooling effect they have on the Earth's climate, potentially contributing to warming. This might also alter regional precipitation patterns due to changes in cloud microphysics.\n",
      "\n",
      "\tBleu: 0.521\n",
      "\tBert: 0.907\n",
      "\tFA Score: 0.989\n",
      "LLM: llama3-70b\n",
      "\tGenerated Answer: A significant decrease in anthropogenic aerosol particles would likely lead to an increase in global temperatures, as aerosols currently cool the planet by reflecting sunlight and reducing cloud droplet concentrations, which in turn increase cloud albedo. This decrease would also alter precipitation patterns, potentially leading to changes in regional climate and weather extremes.\n",
      "\n",
      "\tBleu: 0.500\n",
      "\tBert: 0.913\n",
      "\tFA Score: 0.967\n",
      "LLM: mixtral-8x22b\n",
      "\tGenerated Answer: A significant decrease in anthropogenic aerosol particles would likely result in fewer cloud droplets, leading to less reflection of sunlight and potentially contributing to an increase in global temperatures. This decrease could also alter precipitation patterns, affecting regional climates and ecosystems.\n",
      "\n",
      "\tBleu: 0.531\n",
      "\tBert: 0.909\n",
      "\tFA Score: 0.987\n",
      "LLM: gemma-27b\n",
      "\tGenerated Answer: A decrease in anthropogenic aerosols would likely lead to fewer, larger cloud droplets. This would result in less cloud reflectivity, potentially leading to increased warming.\n",
      "\n",
      "\tBleu: 0.363\n",
      "\tBert: 0.915\n",
      "\tFA Score: 0.976\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from qa import qa_utils\n",
    "from qa.qa_agent import QAAgent\n",
    "from qa.qa_fewshot_agent import QAFewshotAgent\n",
    "from qa.qa_rag_agent import QARagAgent\n",
    "from llm.openai_llm import OpenAIILLM\n",
    "from llm.together_ai_llm import TogetherAILLM\n",
    "\n",
    "ind = random.randint(0, len(ffq_df)-1)\n",
    "question = list(ffq_df['Question'])[ind]\n",
    "reference_answer = list(ffq_df['Answer'])[ind]\n",
    "\n",
    "# Default LLM Agents\n",
    "qa_agents = [\n",
    "    QAAgent(OpenAIILLM('gpt-3.5-turbo')),\n",
    "    QAAgent(OpenAIILLM('gpt-4o')),\n",
    "    QAAgent(TogetherAILLM('llama3-70b')),\n",
    "    QAAgent(TogetherAILLM('mixtral-8x22b')),\n",
    "    QAAgent(TogetherAILLM('gemma-27b'))\n",
    "]\n",
    "\n",
    "# LLM Agents that answer with Few-shot prompting\n",
    "# qa_agents = [\n",
    "#     QAFewshotAgent(OpenAIILLM('gpt-3.5-turbo')),\n",
    "#     QAFewshotAgent(OpenAIILLM('gpt-4o')),\n",
    "#     QAFewshotAgent(TogetherAILLM('llama3-70b')),\n",
    "#     QAFewshotAgent(TogetherAILLM('mixtral-7b')),\n",
    "#     QAFewshotAgent(TogetherAILLM('gemma-27b'))\n",
    "# ]\n",
    "\n",
    "# LLM Agents that answer with RAG prompting. Need to create a chroma vectordb for these to work\n",
    "# qa_agents = [\n",
    "#     QARagAgent(OpenAIILLM('gpt-3.5-turbo')),\n",
    "#     QARagAgent(OpenAIILLM('gpt-4o')),\n",
    "#     QARagAgent(TogetherAILLM('llama3-70b')),\n",
    "#     QARagAgent(TogetherAILLM('mixtral-8x22b')),\n",
    "#     QARagAgent(TogetherAILLM('gemma-27b'))\n",
    "# ]\n",
    "\n",
    "qa_utils.get_metrics_for_question(qa_agents, question, reference_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "result_dir = 'results/freeform'\n",
    "\n",
    "num_trials = 3\n",
    "for i in range(num_trials):\n",
    "    print(f'\\nRunning trial {i+1}\\n')\n",
    "    trial_dir = os.path.join(result_dir, f'trial_{i+1}')\n",
    "    for agent in qa_agents:\n",
    "        print(f'Answering with {agent.name}')\n",
    "        qa_utils.generate_and_save_answer(agent, ffq_df, trial_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qa import qa_utils\n",
    "\n",
    "qa_utils.evaluate_result(result_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
